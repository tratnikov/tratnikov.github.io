{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greatest-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as mp\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blond-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "boxed-heating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_0__mal_1</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.627417</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "mean radius              569.0   14.127292    3.524049    6.981000   \n",
       "mean texture             569.0   19.289649    4.301036    9.710000   \n",
       "mean perimeter           569.0   91.969033   24.298981   43.790000   \n",
       "mean area                569.0  654.889104  351.914129  143.500000   \n",
       "mean smoothness          569.0    0.096360    0.014064    0.052630   \n",
       "mean compactness         569.0    0.104341    0.052813    0.019380   \n",
       "mean concavity           569.0    0.088799    0.079720    0.000000   \n",
       "mean concave points      569.0    0.048919    0.038803    0.000000   \n",
       "mean symmetry            569.0    0.181162    0.027414    0.106000   \n",
       "mean fractal dimension   569.0    0.062798    0.007060    0.049960   \n",
       "radius error             569.0    0.405172    0.277313    0.111500   \n",
       "texture error            569.0    1.216853    0.551648    0.360200   \n",
       "perimeter error          569.0    2.866059    2.021855    0.757000   \n",
       "area error               569.0   40.337079   45.491006    6.802000   \n",
       "smoothness error         569.0    0.007041    0.003003    0.001713   \n",
       "compactness error        569.0    0.025478    0.017908    0.002252   \n",
       "concavity error          569.0    0.031894    0.030186    0.000000   \n",
       "concave points error     569.0    0.011796    0.006170    0.000000   \n",
       "symmetry error           569.0    0.020542    0.008266    0.007882   \n",
       "fractal dimension error  569.0    0.003795    0.002646    0.000895   \n",
       "worst radius             569.0   16.269190    4.833242    7.930000   \n",
       "worst texture            569.0   25.677223    6.146258   12.020000   \n",
       "worst perimeter          569.0  107.261213   33.602542   50.410000   \n",
       "worst area               569.0  880.583128  569.356993  185.200000   \n",
       "worst smoothness         569.0    0.132369    0.022832    0.071170   \n",
       "worst compactness        569.0    0.254265    0.157336    0.027290   \n",
       "worst concavity          569.0    0.272188    0.208624    0.000000   \n",
       "worst concave points     569.0    0.114606    0.065732    0.000000   \n",
       "worst symmetry           569.0    0.290076    0.061867    0.156500   \n",
       "worst fractal dimension  569.0    0.083946    0.018061    0.055040   \n",
       "benign_0__mal_1          569.0    0.627417    0.483918    0.000000   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "mean radius               11.700000   13.370000    15.780000    28.11000  \n",
       "mean texture              16.170000   18.840000    21.800000    39.28000  \n",
       "mean perimeter            75.170000   86.240000   104.100000   188.50000  \n",
       "mean area                420.300000  551.100000   782.700000  2501.00000  \n",
       "mean smoothness            0.086370    0.095870     0.105300     0.16340  \n",
       "mean compactness           0.064920    0.092630     0.130400     0.34540  \n",
       "mean concavity             0.029560    0.061540     0.130700     0.42680  \n",
       "mean concave points        0.020310    0.033500     0.074000     0.20120  \n",
       "mean symmetry              0.161900    0.179200     0.195700     0.30400  \n",
       "mean fractal dimension     0.057700    0.061540     0.066120     0.09744  \n",
       "radius error               0.232400    0.324200     0.478900     2.87300  \n",
       "texture error              0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter error            1.606000    2.287000     3.357000    21.98000  \n",
       "area error                17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness error           0.005169    0.006380     0.008146     0.03113  \n",
       "compactness error          0.013080    0.020450     0.032450     0.13540  \n",
       "concavity error            0.015090    0.025890     0.042050     0.39600  \n",
       "concave points error       0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry error             0.015160    0.018730     0.023480     0.07895  \n",
       "fractal dimension error    0.002248    0.003187     0.004558     0.02984  \n",
       "worst radius              13.010000   14.970000    18.790000    36.04000  \n",
       "worst texture             21.080000   25.410000    29.720000    49.54000  \n",
       "worst perimeter           84.110000   97.660000   125.400000   251.20000  \n",
       "worst area               515.300000  686.500000  1084.000000  4254.00000  \n",
       "worst smoothness           0.116600    0.131300     0.146000     0.22260  \n",
       "worst compactness          0.147200    0.211900     0.339100     1.05800  \n",
       "worst concavity            0.114500    0.226700     0.382900     1.25200  \n",
       "worst concave points       0.064930    0.099930     0.161400     0.29100  \n",
       "worst symmetry             0.250400    0.282200     0.317900     0.66380  \n",
       "worst fractal dimension    0.071460    0.080040     0.092080     0.20750  \n",
       "benign_0__mal_1            0.000000    1.000000     1.000000     1.00000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "romantic-latitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='benign_0__mal_1', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='benign_0__mal_1',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "whole-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst concave points      -0.793566\n",
       "worst perimeter           -0.782914\n",
       "mean concave points       -0.776614\n",
       "worst radius              -0.776454\n",
       "mean perimeter            -0.742636\n",
       "worst area                -0.733825\n",
       "mean radius               -0.730029\n",
       "mean area                 -0.708984\n",
       "mean concavity            -0.696360\n",
       "worst concavity           -0.659610\n",
       "mean compactness          -0.596534\n",
       "worst compactness         -0.590998\n",
       "radius error              -0.567134\n",
       "perimeter error           -0.556141\n",
       "area error                -0.548236\n",
       "worst texture             -0.456903\n",
       "worst smoothness          -0.421465\n",
       "worst symmetry            -0.416294\n",
       "mean texture              -0.415185\n",
       "concave points error      -0.408042\n",
       "mean smoothness           -0.358560\n",
       "mean symmetry             -0.330499\n",
       "worst fractal dimension   -0.323872\n",
       "compactness error         -0.292999\n",
       "concavity error           -0.253730\n",
       "fractal dimension error   -0.077972\n",
       "symmetry error             0.006522\n",
       "texture error              0.008303\n",
       "mean fractal dimension     0.012838\n",
       "smoothness error           0.067016\n",
       "benign_0__mal_1            1.000000\n",
       "Name: benign_0__mal_1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['benign_0__mal_1'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "selected-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1',axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "analyzed-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "occupied-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "associate-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "protecting-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "municipal-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "split-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "demonstrated-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "right-channel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "owned-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) #binary classification\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "weekly-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6704 - val_loss: 0.6481\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.6040\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5779 - val_loss: 0.5561\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.5077\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.4598\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4096\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.3668\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.3287\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3265 - val_loss: 0.2972\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2987 - val_loss: 0.2691\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2745 - val_loss: 0.2454\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2550 - val_loss: 0.2242\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2351 - val_loss: 0.2041\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.1906\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2081 - val_loss: 0.1801\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.1695\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1619\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1750 - val_loss: 0.1520\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1674 - val_loss: 0.1476\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1393\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 0.1346\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1410 - val_loss: 0.1312\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1367 - val_loss: 0.1277\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1270\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1201\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.1210\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1186\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.1124\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.1146\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.1088\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.1098\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.1109\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.1078\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.1077\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.1044\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.1083\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.1004\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.1109\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.1012\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1049\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.1036\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.1009\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.1006\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.1020\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.1027\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.1007\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0996\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0981\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.1029\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0981\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0971\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.1037\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0997\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.1021\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0991\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.1009\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0996\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.1046\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.1044\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.1038\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0948\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.1052\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0971\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0990\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.1008\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.1006\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.1000\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.1056\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0949\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.1009\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0950\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.1001\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0987\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0956\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.1136\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0969\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0988\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.1058\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.1079\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.1056\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0987\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0958\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.1078\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0975\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.1084\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.1029\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.1080\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0997\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0992\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.1062\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.1023\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.1044\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.1024\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.1024\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.1018\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.1098\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.1024\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.1059\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.1026\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.1074\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0981\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.1099\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.1022\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.1047\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.1041\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0999\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.1081\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.1031\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.1050\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0988\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.1081\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.1149\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0969\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.1258\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0971\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.1206\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.1021\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.1051\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.1061\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.1062\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0979\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.1158\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.1044\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.1094\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0988\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.1075\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.1035\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.1173\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.1022\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.1025\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.1123\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.1109\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.1044\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.1142\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.1099\n",
      "Epoch 136/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.1130\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.1129\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.1066\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.1086\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.1092\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.1128\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.1149\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.1052\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.1074\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.1173\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.1084\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.1103\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.1128\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.1088\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.1144\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.1080\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.1251\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.1082\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.1244\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.1128\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.1204\n",
      "Epoch 157/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.1033\n",
      "Epoch 158/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.1100\n",
      "Epoch 159/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.1134\n",
      "Epoch 160/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.1164\n",
      "Epoch 161/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.1114\n",
      "Epoch 162/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.1109\n",
      "Epoch 163/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.1188\n",
      "Epoch 164/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.1107\n",
      "Epoch 165/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.1198\n",
      "Epoch 166/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.1067\n",
      "Epoch 167/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.1249\n",
      "Epoch 168/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.1051\n",
      "Epoch 169/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.1344\n",
      "Epoch 170/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.1069\n",
      "Epoch 171/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.1222\n",
      "Epoch 172/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.1127\n",
      "Epoch 173/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.1237\n",
      "Epoch 174/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.1096\n",
      "Epoch 175/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.1152\n",
      "Epoch 176/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.1176\n",
      "Epoch 177/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.1216\n",
      "Epoch 178/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.1157\n",
      "Epoch 179/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.1235\n",
      "Epoch 180/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.1117\n",
      "Epoch 181/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.1174\n",
      "Epoch 182/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.1196\n",
      "Epoch 183/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.1121\n",
      "Epoch 184/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.1340\n",
      "Epoch 185/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.1167\n",
      "Epoch 186/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.1227\n",
      "Epoch 187/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.1196\n",
      "Epoch 188/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.1270\n",
      "Epoch 189/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.1144\n",
      "Epoch 190/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.1211\n",
      "Epoch 191/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.1189\n",
      "Epoch 192/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.1163\n",
      "Epoch 193/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.1245\n",
      "Epoch 194/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.1150\n",
      "Epoch 195/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.1274\n",
      "Epoch 196/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.1146\n",
      "Epoch 197/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.1141\n",
      "Epoch 198/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.1214\n",
      "Epoch 199/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.1279\n",
      "Epoch 200/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.1246\n",
      "Epoch 201/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.1242\n",
      "Epoch 202/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.1195\n",
      "Epoch 203/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.1141\n",
      "Epoch 204/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.1301\n",
      "Epoch 205/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.1232\n",
      "Epoch 206/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.1188\n",
      "Epoch 207/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.1199\n",
      "Epoch 208/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.1315\n",
      "Epoch 209/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.1131\n",
      "Epoch 210/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.1306\n",
      "Epoch 211/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.1296\n",
      "Epoch 212/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.1223\n",
      "Epoch 213/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.1254\n",
      "Epoch 214/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.1182\n",
      "Epoch 215/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.1261\n",
      "Epoch 216/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.1342\n",
      "Epoch 217/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.1226\n",
      "Epoch 218/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.1338\n",
      "Epoch 219/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.1244\n",
      "Epoch 220/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.1333\n",
      "Epoch 221/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.1334\n",
      "Epoch 222/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.1355\n",
      "Epoch 223/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.1193\n",
      "Epoch 224/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.1393\n",
      "Epoch 225/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.1249\n",
      "Epoch 226/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.1352\n",
      "Epoch 227/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.1318\n",
      "Epoch 228/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.1358\n",
      "Epoch 229/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.1329\n",
      "Epoch 230/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.1258\n",
      "Epoch 231/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.1428\n",
      "Epoch 232/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.1200\n",
      "Epoch 233/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.1435\n",
      "Epoch 234/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.1316\n",
      "Epoch 235/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.1416\n",
      "Epoch 236/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.1246\n",
      "Epoch 237/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.1356\n",
      "Epoch 238/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.1318\n",
      "Epoch 239/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.1283\n",
      "Epoch 240/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.1514\n",
      "Epoch 241/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.1282\n",
      "Epoch 242/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.1305\n",
      "Epoch 243/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.1358\n",
      "Epoch 244/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.1508\n",
      "Epoch 245/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.1315\n",
      "Epoch 246/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.1408\n",
      "Epoch 247/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.1464\n",
      "Epoch 248/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.1379\n",
      "Epoch 249/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.1376\n",
      "Epoch 250/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.1372\n",
      "Epoch 251/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.1783\n",
      "Epoch 252/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.1248\n",
      "Epoch 253/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.1788\n",
      "Epoch 254/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.1291\n",
      "Epoch 255/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.1370\n",
      "Epoch 256/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.1383\n",
      "Epoch 257/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.1481\n",
      "Epoch 258/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.1254\n",
      "Epoch 259/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.1462\n",
      "Epoch 260/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.1306\n",
      "Epoch 261/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.1615\n",
      "Epoch 262/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.1367\n",
      "Epoch 263/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.1475\n",
      "Epoch 264/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.1307\n",
      "Epoch 265/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.1484\n",
      "Epoch 266/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1316\n",
      "Epoch 267/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.1503\n",
      "Epoch 268/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1427\n",
      "Epoch 269/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1593\n",
      "Epoch 270/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.1480\n",
      "Epoch 271/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1474\n",
      "Epoch 272/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.1376\n",
      "Epoch 273/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.2300\n",
      "Epoch 274/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.1528\n",
      "Epoch 275/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1461\n",
      "Epoch 276/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1468\n",
      "Epoch 277/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1487\n",
      "Epoch 278/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1534\n",
      "Epoch 279/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1424\n",
      "Epoch 280/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1518\n",
      "Epoch 281/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1478\n",
      "Epoch 282/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1641\n",
      "Epoch 283/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.1506\n",
      "Epoch 284/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1453\n",
      "Epoch 285/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1579\n",
      "Epoch 286/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1546\n",
      "Epoch 287/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1650\n",
      "Epoch 288/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1518\n",
      "Epoch 289/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1667\n",
      "Epoch 290/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1643\n",
      "Epoch 291/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1551\n",
      "Epoch 292/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1663\n",
      "Epoch 293/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1637\n",
      "Epoch 294/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1508\n",
      "Epoch 295/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1651\n",
      "Epoch 296/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1660\n",
      "Epoch 297/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1521\n",
      "Epoch 298/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1752\n",
      "Epoch 299/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.1584\n",
      "Epoch 300/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1576\n",
      "Epoch 301/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1598\n",
      "Epoch 302/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1701\n",
      "Epoch 303/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1691\n",
      "Epoch 304/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.1427\n",
      "Epoch 305/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.2262\n",
      "Epoch 306/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.1504\n",
      "Epoch 307/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2044\n",
      "Epoch 308/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1440\n",
      "Epoch 309/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1674\n",
      "Epoch 310/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1512\n",
      "Epoch 311/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1688\n",
      "Epoch 312/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1718\n",
      "Epoch 313/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1683\n",
      "Epoch 314/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1572\n",
      "Epoch 315/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1817\n",
      "Epoch 316/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1686\n",
      "Epoch 317/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1584\n",
      "Epoch 318/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.2088\n",
      "Epoch 319/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1617\n",
      "Epoch 320/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1858\n",
      "Epoch 321/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1676\n",
      "Epoch 322/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1826\n",
      "Epoch 323/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1679\n",
      "Epoch 324/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1715\n",
      "Epoch 325/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1967\n",
      "Epoch 326/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1647\n",
      "Epoch 327/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1899\n",
      "Epoch 328/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1616\n",
      "Epoch 329/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.2050\n",
      "Epoch 330/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1677\n",
      "Epoch 331/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1835\n",
      "Epoch 332/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1807\n",
      "Epoch 333/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1726\n",
      "Epoch 334/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1919\n",
      "Epoch 335/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1693\n",
      "Epoch 336/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1875\n",
      "Epoch 337/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1731\n",
      "Epoch 338/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1933\n",
      "Epoch 339/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1771\n",
      "Epoch 340/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1971\n",
      "Epoch 341/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1741\n",
      "Epoch 342/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1790\n",
      "Epoch 343/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.2266\n",
      "Epoch 344/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1784\n",
      "Epoch 345/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.2018\n",
      "Epoch 346/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1915\n",
      "Epoch 347/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1985\n",
      "Epoch 348/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1940\n",
      "Epoch 349/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1932\n",
      "Epoch 350/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.1876\n",
      "Epoch 351/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.2025\n",
      "Epoch 352/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.2045\n",
      "Epoch 353/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1735\n",
      "Epoch 354/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.2048\n",
      "Epoch 355/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1959\n",
      "Epoch 356/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.1864\n",
      "Epoch 357/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.2087\n",
      "Epoch 358/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.1935\n",
      "Epoch 359/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.2023\n",
      "Epoch 360/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1838\n",
      "Epoch 361/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.2005\n",
      "Epoch 362/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1840\n",
      "Epoch 363/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1989\n",
      "Epoch 364/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.2161\n",
      "Epoch 365/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.2025\n",
      "Epoch 366/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.1855\n",
      "Epoch 367/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.2097\n",
      "Epoch 368/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.2409\n",
      "Epoch 369/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1816\n",
      "Epoch 370/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.3192\n",
      "Epoch 371/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1822\n",
      "Epoch 372/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.4006\n",
      "Epoch 373/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.1820\n",
      "Epoch 374/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.2754\n",
      "Epoch 375/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.1957\n",
      "Epoch 376/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.2303\n",
      "Epoch 377/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.2033\n",
      "Epoch 378/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.2064\n",
      "Epoch 379/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.1982\n",
      "Epoch 380/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.2078\n",
      "Epoch 381/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.2152\n",
      "Epoch 382/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.2151\n",
      "Epoch 383/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.2129\n",
      "Epoch 384/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.2233\n",
      "Epoch 385/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.2255\n",
      "Epoch 386/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.2072\n",
      "Epoch 387/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.2052\n",
      "Epoch 388/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.2311\n",
      "Epoch 389/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.2107\n",
      "Epoch 390/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.2183\n",
      "Epoch 391/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.2351\n",
      "Epoch 392/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.2102\n",
      "Epoch 393/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.2335\n",
      "Epoch 394/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.2306\n",
      "Epoch 395/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.2100\n",
      "Epoch 396/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.2212\n",
      "Epoch 397/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.2257\n",
      "Epoch 398/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.2071\n",
      "Epoch 399/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.2669\n",
      "Epoch 400/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.2034\n",
      "Epoch 401/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.2402\n",
      "Epoch 402/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.2195\n",
      "Epoch 403/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.2262\n",
      "Epoch 404/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.2270\n",
      "Epoch 405/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.2097\n",
      "Epoch 406/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.2251\n",
      "Epoch 407/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.2354\n",
      "Epoch 408/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.2392\n",
      "Epoch 409/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.2081\n",
      "Epoch 410/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.2637\n",
      "Epoch 411/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.2348\n",
      "Epoch 412/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.2220\n",
      "Epoch 413/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.2381\n",
      "Epoch 414/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.2394\n",
      "Epoch 415/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.2268\n",
      "Epoch 416/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.2340\n",
      "Epoch 417/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.2435\n",
      "Epoch 418/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.2368\n",
      "Epoch 419/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.2175\n",
      "Epoch 420/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.2750\n",
      "Epoch 421/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.2260\n",
      "Epoch 422/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.2678\n",
      "Epoch 423/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.2276\n",
      "Epoch 424/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.2600\n",
      "Epoch 425/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.2230\n",
      "Epoch 426/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.2628\n",
      "Epoch 427/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.2273\n",
      "Epoch 428/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.2613\n",
      "Epoch 429/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.2298\n",
      "Epoch 430/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.2544\n",
      "Epoch 431/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.2234\n",
      "Epoch 432/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.2861\n",
      "Epoch 433/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.2278\n",
      "Epoch 434/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.2421\n",
      "Epoch 435/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.2559\n",
      "Epoch 436/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.2288\n",
      "Epoch 437/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.2412\n",
      "Epoch 438/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.2524\n",
      "Epoch 439/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2483\n",
      "Epoch 440/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.2664\n",
      "Epoch 441/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2467\n",
      "Epoch 442/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.2654\n",
      "Epoch 443/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2387\n",
      "Epoch 444/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.2781\n",
      "Epoch 445/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.2414\n",
      "Epoch 446/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.2838\n",
      "Epoch 447/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.2543\n",
      "Epoch 448/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2469\n",
      "Epoch 449/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2847\n",
      "Epoch 450/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.2539\n",
      "Epoch 451/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.2768\n",
      "Epoch 452/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.2481\n",
      "Epoch 453/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.2542\n",
      "Epoch 454/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.2543\n",
      "Epoch 455/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.3058\n",
      "Epoch 456/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.2305\n",
      "Epoch 457/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.2653\n",
      "Epoch 458/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.2677\n",
      "Epoch 459/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.2677\n",
      "Epoch 460/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2625\n",
      "Epoch 461/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.2809\n",
      "Epoch 462/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.2641\n",
      "Epoch 463/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.2767\n",
      "Epoch 464/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.2591\n",
      "Epoch 465/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.2740\n",
      "Epoch 466/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.2885\n",
      "Epoch 467/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.2547\n",
      "Epoch 468/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2992\n",
      "Epoch 469/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.2614\n",
      "Epoch 470/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.2841\n",
      "Epoch 471/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.2482\n",
      "Epoch 472/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.3392\n",
      "Epoch 473/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.2395\n",
      "Epoch 474/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.2966\n",
      "Epoch 475/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.2393\n",
      "Epoch 476/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.3299\n",
      "Epoch 477/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.3342\n",
      "Epoch 478/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.2366\n",
      "Epoch 479/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.2990\n",
      "Epoch 480/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.2553\n",
      "Epoch 481/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.3039\n",
      "Epoch 482/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.2839\n",
      "Epoch 483/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.2517\n",
      "Epoch 484/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.3011\n",
      "Epoch 485/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.2822\n",
      "Epoch 486/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.2869\n",
      "Epoch 487/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.2796\n",
      "Epoch 488/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.3051\n",
      "Epoch 489/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.2979\n",
      "Epoch 490/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.2654\n",
      "Epoch 491/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.3009\n",
      "Epoch 492/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.2940\n",
      "Epoch 493/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.2760\n",
      "Epoch 494/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.2915\n",
      "Epoch 495/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.2920\n",
      "Epoch 496/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.2949\n",
      "Epoch 497/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.2901\n",
      "Epoch 498/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.2837\n",
      "Epoch 499/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.3199\n",
      "Epoch 500/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.2474\n",
      "Epoch 501/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.3648\n",
      "Epoch 502/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.2657\n",
      "Epoch 503/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.3363\n",
      "Epoch 504/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.2989\n",
      "Epoch 505/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.2868\n",
      "Epoch 506/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.3129\n",
      "Epoch 507/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.3021\n",
      "Epoch 508/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.3263\n",
      "Epoch 509/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.2916\n",
      "Epoch 510/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.2999\n",
      "Epoch 511/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.3144\n",
      "Epoch 512/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.3140\n",
      "Epoch 513/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.2969\n",
      "Epoch 514/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.3378\n",
      "Epoch 515/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.2945\n",
      "Epoch 516/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.3200\n",
      "Epoch 517/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.3315\n",
      "Epoch 518/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.3113\n",
      "Epoch 519/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.3229\n",
      "Epoch 520/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.3104\n",
      "Epoch 521/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.3240\n",
      "Epoch 522/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.3088\n",
      "Epoch 523/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.3095\n",
      "Epoch 524/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.3192\n",
      "Epoch 525/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.3009\n",
      "Epoch 526/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.3074\n",
      "Epoch 527/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.3131\n",
      "Epoch 528/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.3048\n",
      "Epoch 529/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.3442\n",
      "Epoch 530/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.2975\n",
      "Epoch 531/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.3331\n",
      "Epoch 532/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.3306\n",
      "Epoch 533/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.3030\n",
      "Epoch 534/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.3893\n",
      "Epoch 535/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.3005\n",
      "Epoch 536/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.3676\n",
      "Epoch 537/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.2974\n",
      "Epoch 538/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.3493\n",
      "Epoch 539/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.2582\n",
      "Epoch 540/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.4069\n",
      "Epoch 541/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.3020\n",
      "Epoch 542/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.3499\n",
      "Epoch 543/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.3312\n",
      "Epoch 544/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.2987\n",
      "Epoch 545/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.3410\n",
      "Epoch 546/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.3182\n",
      "Epoch 547/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.003 - 0s 2ms/step - loss: 0.0026 - val_loss: 0.3215\n",
      "Epoch 548/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.3543\n",
      "Epoch 549/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.3456\n",
      "Epoch 550/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.3541\n",
      "Epoch 551/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.3160\n",
      "Epoch 552/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.3481\n",
      "Epoch 553/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.3218\n",
      "Epoch 554/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.3175\n",
      "Epoch 555/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.4049\n",
      "Epoch 556/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.3036\n",
      "Epoch 557/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.4155\n",
      "Epoch 558/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.3021\n",
      "Epoch 559/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.3356\n",
      "Epoch 560/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.3301\n",
      "Epoch 561/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.3285\n",
      "Epoch 562/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.3352\n",
      "Epoch 563/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3278\n",
      "Epoch 564/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3490\n",
      "Epoch 565/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.3408\n",
      "Epoch 566/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.3311\n",
      "Epoch 567/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3332\n",
      "Epoch 568/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3507\n",
      "Epoch 569/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.3268\n",
      "Epoch 570/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.3567\n",
      "Epoch 571/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3435\n",
      "Epoch 572/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.3461\n",
      "Epoch 573/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.3454\n",
      "Epoch 574/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3396\n",
      "Epoch 575/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.3628\n",
      "Epoch 576/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.3422\n",
      "Epoch 577/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.3835\n",
      "Epoch 578/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.3273\n",
      "Epoch 579/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.3485\n",
      "Epoch 580/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.3385\n",
      "Epoch 581/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.3859\n",
      "Epoch 582/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.3437\n",
      "Epoch 583/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.3604\n",
      "Epoch 584/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.3403\n",
      "Epoch 585/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.4486\n",
      "Epoch 586/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.2973\n",
      "Epoch 587/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.4039\n",
      "Epoch 588/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.3180\n",
      "Epoch 589/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.3404\n",
      "Epoch 590/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.3573\n",
      "Epoch 591/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.3266\n",
      "Epoch 592/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.3962\n",
      "Epoch 593/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.3406\n",
      "Epoch 594/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.3726\n",
      "Epoch 595/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.3475\n",
      "Epoch 596/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.3398\n",
      "Epoch 597/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.4081\n",
      "Epoch 598/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3779\n",
      "Epoch 599/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.3894\n",
      "Epoch 600/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.3363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23c6ea46f40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=600,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "quarterly-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.Datarame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "excellent-delivery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "intensive-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) #binary classification\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "authorized-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sustained-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "roman-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6853 - val_loss: 0.6705\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6616 - val_loss: 0.6505\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6381 - val_loss: 0.6236\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.5844\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5619 - val_loss: 0.5321\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.4679\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.4090\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 0.3537\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3092\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.2745\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2725 - val_loss: 0.2459\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2465 - val_loss: 0.2233\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2230 - val_loss: 0.2016\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2044 - val_loss: 0.1869\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1882 - val_loss: 0.1721\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1687\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1636 - val_loss: 0.1508\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1449\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1406\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1347\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.1264\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1228 - val_loss: 0.1351\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1189\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.1329\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1137\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.1163\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.1150\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.1102\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.1154\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.1119\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.1093\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.1152\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.1087\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.1116\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.1069\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.1169\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.1045\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.1094\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.1064\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.1153\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.1043\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.1060\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.1066\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.1061\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.1082\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.1109\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.1065\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.1109\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.1078\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.1051\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.1097\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.1074\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.1206\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.1086\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.1161\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.1070\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.1142\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.1100\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.1100\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.1113\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.1115\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.1129\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.1155\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.1115\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.1125\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.1192\n",
      "Epoch 00066: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23c716f36a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=600,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "checked-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid')) #binary classification\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "interested-discipline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6672 - val_loss: 0.6463\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6615 - val_loss: 0.6258\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6354 - val_loss: 0.6038\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.5775\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5942 - val_loss: 0.5493\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5661 - val_loss: 0.5176\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.4823\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.4482\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.4210\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.3954\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.3712\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.3393\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 0.3221\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.3065\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.2849\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3538 - val_loss: 0.2697\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.2542\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.2373\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3216 - val_loss: 0.2249\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.2099\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2637 - val_loss: 0.2115\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.2032\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2789 - val_loss: 0.1907\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2723 - val_loss: 0.1904\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2520 - val_loss: 0.1960\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2512 - val_loss: 0.1734\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2499 - val_loss: 0.1653\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2398 - val_loss: 0.1577\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2662 - val_loss: 0.1711\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2441 - val_loss: 0.1583\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2270 - val_loss: 0.1554\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2322 - val_loss: 0.1462\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2142 - val_loss: 0.1407\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1941 - val_loss: 0.1423\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2241 - val_loss: 0.1366\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2204 - val_loss: 0.1319\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2086 - val_loss: 0.1325\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2024 - val_loss: 0.1351\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1855 - val_loss: 0.1310\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1767 - val_loss: 0.1293\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1532 - val_loss: 0.1243\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1883 - val_loss: 0.1260\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1737 - val_loss: 0.1193\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1931 - val_loss: 0.1201\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1771 - val_loss: 0.1164\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1922 - val_loss: 0.1189\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1728 - val_loss: 0.1211\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1726 - val_loss: 0.1135\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1294\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 0.1128\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1566 - val_loss: 0.1098\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1573 - val_loss: 0.1069\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1140\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1571 - val_loss: 0.1066\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1038\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1772 - val_loss: 0.1090\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1386 - val_loss: 0.1054\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1281 - val_loss: 0.1071\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.1021\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1069\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1003\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.0965\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1155\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1370 - val_loss: 0.0989\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1426 - val_loss: 0.1051\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1009\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.0948\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1062\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1260 - val_loss: 0.1158\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 0.0972\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.0949\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.1059\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1017\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1006\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1297 - val_loss: 0.1010\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.1000\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1233 - val_loss: 0.0975\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1148 - val_loss: 0.0970\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1130 - val_loss: 0.1004\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.0978\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1212 - val_loss: 0.0986\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.0937\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.1006\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1092 - val_loss: 0.1063\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.1131\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.1088\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.0961\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.1060\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.0995\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.0926\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1134 - val_loss: 0.1040\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.0978\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.0904\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.0938\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.0939\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.1057\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.0921\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1017\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.0902\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 0.0963\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1058\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.0918\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1199 - val_loss: 0.0937\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.1057\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1062 - val_loss: 0.0983\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0920\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 0.1043\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0950 - val_loss: 0.0939\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.0901\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.1120\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.0989\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.0948\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1146\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.1091\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.0988\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.1002\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.1005\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1116 - val_loss: 0.0962\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1006\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.1043\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.1200\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0996\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0970\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.1127\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0992\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.1017\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.1091\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0974\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0988\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.1083\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1014\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.0922\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.1065\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.0990\n",
      "Epoch 00134: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23c71ab3b20>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=600,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "lightweight-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "western-expression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faced-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "textile-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "built-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        55\n",
      "           1       0.99      0.98      0.98        88\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "liquid-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  1]\n",
      " [ 2 86]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
