{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "requested-kitchen",
   "metadata": {},
   "source": [
    "**Cleaning Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "located-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text\n",
    "text_data = [\" Interrobang. By Aishwarya Henriette \",\n",
    "\"Parking And Going. By Karl Gautier\",\n",
    "\" Today Is The night. By Jarek Prakash \"]\n",
    "# Strip whitespaces\n",
    "strip_whitespace = [string.strip() for string in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "massive-lottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang. By Aishwarya Henriette',\n",
       " 'Parking And Going. By Karl Gautier',\n",
       " 'Today Is The night. By Jarek Prakash']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove periods\n",
    "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-oakland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang By Aishwarya Henriette',\n",
       " 'Parking And Going By Karl Gautier',\n",
       " 'Today Is The night By Jarek Prakash']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "theoretical-groove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTERROBANG BY AISHWARYA HENRIETTE',\n",
       " 'PARKING AND GOING BY KARL GAUTIER',\n",
       " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We also create and apply a custom transformation function:\n",
    "# Create function\n",
    "def capitalizer(string):\n",
    "    return string.upper()\n",
    "# Apply function\n",
    "[capitalizer(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "basic-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we can use regular expressions to make powerful string operations:\n",
    "# Import library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "valued-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def replace_letters_with_X(string: str) -> str:\n",
    "    return re.sub(r\"[a-zA-Z]\", \"X\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elementary-gregory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
       " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
       " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function\n",
    "[replace_letters_with_X(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-consideration",
   "metadata": {},
   "source": [
    "**Parsing and Cleaning HTML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bulgarian-county",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Masego Azra'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<div class='full_name'><span style='font-weight:bold'>\n",
    "Masego</span> Azra</div>\"\n",
    "\"\"\"\n",
    "# Parse html\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "# Find the div with the class \"full_name\", show text\n",
    "soup.find(\"div\", { \"class\" : \"full_name\" }).text\n",
    "'Masego Azra'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-heavy",
   "metadata": {},
   "source": [
    "**Removing Punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import unicodedata\n",
    "import sys\n",
    "# Create text\n",
    "text_data = ['Hi!!!! I. Love. This. Song....',\n",
    "'10000% Agree!!!! #LoveIT',\n",
    "'Right?!?!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "if unicodedata.category(chr(i)).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "motivated-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each string, remove any punctuation characters\n",
    "[string.translate(punctuation) for string in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-helmet",
   "metadata": {},
   "source": [
    "**Tokenizing Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eligible-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opposed-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text\n",
    "string = \"The science of today. Is the technology of tomorrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fancy-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "tokens = nltk.word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unsigned-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\max\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "legitimate-berry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'science',\n",
       " 'of',\n",
       " 'today',\n",
       " '.',\n",
       " 'Is',\n",
       " 'the',\n",
       " 'technology',\n",
       " 'of',\n",
       " 'tomorrow']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "juvenile-cruise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today.', 'Is the technology of tomorrow']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-screw",
   "metadata": {},
   "source": [
    "**Removing Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deadly-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "regular-aerospace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\max\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unnecessary-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word tokens\n",
    "tokenized_words = ['i',\n",
    "'am',\n",
    "'going',\n",
    "'to',\n",
    "'go',\n",
    "'to',\n",
    "'the',\n",
    "'store',\n",
    "'and',\n",
    "'park']\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "strong-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rolled-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-context",
   "metadata": {},
   "source": [
    "**Stemming Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "global-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "original-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word tokens\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "micro-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "independent-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply stemmer\n",
    "[porter.stem(word) for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-duplicate",
   "metadata": {},
   "source": [
    "Stemming reduces a word to its stem by identifying and removing affixes (e.g., gerunds)\n",
    "while keeping the root meaning of the word. For example, both “tradition” and\n",
    "“traditional” have “tradit” as their stem, indicating that while they are different words\n",
    "they represent the same general concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-diversity",
   "metadata": {},
   "source": [
    "**Tagging Parts of Speech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "injured-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sunrise-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text\n",
    "text_data = \"Chris loved outdoor running\"\n",
    "# Use pre-trained part of speech tagger\n",
    "text_tagged = pos_tag(word_tokenize(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "given-wiring",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\max\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "connected-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show parts of speech\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-belle",
   "metadata": {},
   "source": [
    "**Encoding Text as a Bag of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "present-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ordinary-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "'Sweden is best',\n",
    "'Germany beats both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "reserved-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "joined-skirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "powered-ukraine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "organic-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love', 'sweden']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-supervision",
   "metadata": {},
   "source": [
    "**Weighting Word Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "polish-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "'Sweden is best',\n",
    "'Germany beats both'])\n",
    "# Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "forbidden-plastic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show tf-idf feature matrix\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "developmental-stamp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "concerned-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
